@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={1998},
  publisher={MIT press Cambridge}
}

@inproceedings{sutton2000policy,
	title={Policy gradient methods for reinforcement learning with function approximation},
	author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
	booktitle={Advances in neural information processing systems},
	pages={1057--1063},
	year={2000}
}
@article{williams1992simple,
	title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	author={Williams, Ronald J},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={229--256},
	year={1992},
	publisher={Springer}
}
@article{baxter2001infinite,
	title={Infinite-horizon policy-gradient estimation},
	author={Baxter, Jonathan and Bartlett, Peter L},
	journal={Journal of Artificial Intelligence Research},
	volume={15},
	pages={319--350},
	year={2001}
}
@article{cauchy1847methode,
	title={M{\'e}thode g{\'e}n{\'e}rale pour la r{\'e}solution des systemes d'{\'e}quations simultan{\'e}es},
	author={Cauchy, Augustin},
	journal={Comp. Rend. Sci. Paris},
	volume={25},
	number={1847},
	pages={536--538},
	year={1847}
}
@article{robbins1951stochastic,
	title={A stochastic approximation method},
	author={Robbins, Herbert and Monro, Sutton},
	journal={The annals of mathematical statistics},
	pages={400--407},
	year={1951},
	publisher={JSTOR}
}

@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}

@inproceedings{bottou2004large,
	title={Large scale online learning},
	author={Bottou, L{\'e}on and LeCun, Yann},
	booktitle={Advances in neural information processing systems},
	pages={217--224},
	year={2004}
}
@article{agarwal2014lower,
	title={A lower bound for the optimization of finite sums},
	author={Agarwal, Alekh and Bottou, Leon},
	journal={arXiv preprint arXiv:1410.0723},
	year={2014}
}
@inproceedings{roux2012stochastic,
	title={A stochastic gradient method with an exponential convergence \_rate for finite training sets},
	author={Roux, Nicolas L and Schmidt, Mark and Bach, Francis R},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2663--2671},
	year={2012}
}
@inproceedings{johnson2013accelerating,
	title={Accelerating stochastic gradient descent using predictive variance reduction},
	author={Johnson, Rie and Zhang, Tong},
	booktitle={Advances in neural information processing systems},
	pages={315--323},
	year={2013}
}
@inproceedings{defazio2014saga,
	title={Saga: A fast incremental gradient method with support for non-strongly convex composite objectives},
	author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1646--1654},
	year={2014}
}
@inproceedings{defazio2014finito,
	title={Finito: A faster, permutable incremental gradient method for big data problems},
	author={Defazio, Aaron and Domke, Justin and others},
	booktitle={International Conference on Machine Learning},
	pages={1125--1133},
	year={2014}
}
@inproceedings{reddi2016stochastic,
	title={Stochastic variance reduction for nonconvex optimization},
	author={Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
	booktitle={International conference on machine learning},
	pages={314--323},
	year={2016}
}
@book{nesterov2013introductory,
	title={Introductory lectures on convex optimization: A basic course},
	author={Nesterov, Yurii},
	volume={87},
	year={2013},
	publisher={Springer Science \& Business Media}
}
@article{ghadimi2013stochastic,
	title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
	author={Ghadimi, Saeed and Lan, Guanghui},
	journal={SIAM Journal on Optimization},
	volume={23},
	number={4},
	pages={2341--2368},
	year={2013},
	publisher={SIAM}
}

@article{reddi2016fast,
	title={Fast incremental method for nonconvex optimization},
	author={Reddi, Sashank J and Sra, Suvrit and P{\'o}czos, Barnab{\'a}s and Smola, Alex},
	journal={arXiv preprint arXiv:1603.06159},
	year={2016}
}
@techreport{rubinstein1981simulation,
	title={Simulation and the Monte Carlo method},
	author={Rubinstein, Reuven Y Reuven Y},
	year={1981}
}
@article{precup2000eligibility,
	title={Eligibility traces for off-policy policy evaluation},
	author={Precup, Doina},
	journal={Computer Science Department Faculty Publication Series},
	pages={80},
	year={2000}
}

@article{Thomas2017actionbaseline,
  author    = {Philip S. Thomas and
               Emma Brunskill},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation
               and Action-Dependent Baselines},
  journal   = {CoRR},
  volume    = {abs/1706.06643},
  year      = {2017}
}

@article{wu2018variance,
	title={Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines},
	author={Cathy Wu and Aravind Rajeswaran and Yan Duan and Vikash Kumar and Alexandre M Bayen and Sham Kakade and Igor Mordatch and Pieter Abbeel},
	journal={International Conference on Learning Representations},
	year={2018},
	note={accepted as oral presentation},
}

@Article{Peters2008reinf,
  Title                    = {Reinforcement learning of motor skills with policy gradients},
  Author                   = {Jan Peters and Stefan Schaal},
  Journal                  = {Neural Networks},
  Year                     = {2008},
  Number                   = {4},
  Pages                    = {682-697},
  Volume                   = {21}
}

@article{konevcny2016mini,
	title={Mini-batch semi-stochastic gradient descent in the proximal setting},
	author={Kone{\v{c}}n{\`y}, Jakub and Liu, Jie and Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
	journal={IEEE Journal of Selected Topics in Signal Processing},
	volume={10},
	number={2},
	pages={242--255},
	year={2016},
	publisher={IEEE}
}

@inproceedings{harikandeh2015stopwasting,
	title={Stopwasting my gradients: Practical svrg},
	author={Harikandeh, Reza and Ahmed, Mohamed Osama and Virani, Alim and Schmidt, Mark and Kone{\v{c}}n{\`y}, Jakub and Sallinen, Scott},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2251--2259},
	year={2015}
}

@inproceedings{zhao2011analysis,
	title={Analysis and improvement of policy gradient estimation},
	author={Zhao, Tingting and Hachiya, Hirotaka and Niu, Gang and Sugiyama, Masashi},
	booktitle={Advances in Neural Information Processing Systems},
	pages={262--270},
	year={2011}
}

@inproceedings{pirotta2013adaptive,
	title={Adaptive step-size for policy gradient methods},
	author={Pirotta, Matteo and Restelli, Marcello and Bascetta, Luca},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1394--1402},
	year={2013},
}

@inproceedings{allen2016variance,
	title={Variance reduction for faster non-convex optimization},
	author={Allen-Zhu, Zeyuan and Hazan, Elad},
	booktitle={International Conference on Machine Learning},
	pages={699--707},
	year={2016}
}

@article{nemirovskii1983problem,
	title={Problem complexity and method efficiency in optimization},
	author={Nemirovskii, Arkadii and Yudin, David Borisovich and Dawson, Edgar Ronald},
	year={1983},
	publisher={Wiley}
}

@inproceedings{cortes2010learning,
	title={Learning bounds for importance weighting},
	author={Cortes, Corinna and Mansour, Yishay and Mohri, Mehryar},
	booktitle={Advances in neural information processing systems},
	pages={442--450},
	year={2010}
}

@inproceedings{Furmston2012unifying,
  author    = {Thomas Furmston and
               David Barber},
  title     = {A Unifying Perspective of Parametric Policy Search Methods for Markov
               Decision Processes},
  booktitle = {{NIPS}},
  pages     = {2726--2734},
  year      = {2012}
}

@article{pirotta2015lipschitz,
author={Pirotta, Matteo
and Restelli, Marcello
and Bascetta, Luca},
title={Policy gradient in Lipschitz Markov Decision Processes},
journal={Machine Learning},
year={2015},
volume={100},
number={2},
pages={255--283},
issn={1573-0565},
doi={10.1007/s10994-015-5484-1},
}

@inproceedings{thomas2015high,
  title={High-Confidence Off-Policy Evaluation.},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={AAAI},
  pages={3000--3006},
  year={2015}
}

@inproceedings{jurvcivcek2012reinforcement,
  title={Reinforcement learning for spoken dialogue systems using off-policy natural gradient method},
  author={Jur{\v{c}}{\'\i}{\v{c}}ek, Filip},
  booktitle={Spoken Language Technology Workshop (SLT), 2012 IEEE},
  pages={7--12},
  year={2012},
  organization={IEEE}
}

@inproceedings{du2017svrgpe,
  author    = {Simon S. Du and
               Jianshu Chen and
               Lihong Li and
               Lin Xiao and
               Dengyong Zhou},
  title     = {Stochastic Variance Reduction Methods for Policy Evaluation},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {1049--1058},
  publisher = {{PMLR}},
  year      = {2017}
}

@article{xu2017svrgtrpo,
  author    = {Tianbing Xu and
               Qiang Liu and
               Jian Peng},
  title     = {Stochastic Variance Reduction for Policy Gradient Estimation},
  journal   = {CoRR},
  volume    = {abs/1710.06034},
  year      = {2017}
}

@article{peters2008reinforcement,
	title={Reinforcement learning of motor skills with policy gradients},
	author={Peters, Jan and Schaal, Stefan},
	journal={Neural networks},
	volume={21},
	number={4},
	pages={682--697},
	year={2008},
	publisher={Elsevier}
}

@inproceedings{Palaniappan2016svrgsaddle,
  author    = {Palaniappan, Balamurugan and Bach, Francis},
  title     = {Stochastic Variance Reduction Methods for Saddle-Point Problems},
  booktitle = {{NIPS}},
  pages     = {1408--1416},
  year      = {2016}
}
